{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f96ad80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c5f49de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.7300e+02, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [6.1100e+02, 1.4040e+03, 2.8080e+03, ..., 0.0000e+00, 1.8200e+02,\n",
       "        1.0000e+00],\n",
       "       [7.0500e+02, 3.2400e+02, 3.2400e+02, ..., 1.0000e+00, 3.3400e+02,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [2.8671e+04, 1.0800e+03, 1.0800e+03, ..., 0.0000e+00, 2.9000e+01,\n",
       "        0.0000e+00],\n",
       "       [3.1134e+04, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [3.2832e+04, 1.6200e+03, 1.6200e+03, ..., 0.0000e+00, 9.0000e+01,\n",
       "        0.0000e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Audiobooks_data.csv\", header=None)\n",
    "raw_data = data.values\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78fa4243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.160e+03, 2.160e+03, 1.013e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.404e+03, 2.808e+03, 6.660e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.820e+02],\n",
       "       [3.240e+02, 3.240e+02, 1.013e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        3.340e+02],\n",
       "       ...,\n",
       "       [1.080e+03, 1.080e+03, 6.550e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        2.900e+01],\n",
       "       [2.160e+03, 2.160e+03, 6.140e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.620e+03, 1.620e+03, 5.330e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        9.000e+01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_inputs = raw_data[:, 1:-1]\n",
    "unscaled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d49fae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = raw_data[:, -1]\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706635c",
   "metadata": {},
   "source": [
    "## Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fad2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2237"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_one = targets.sum()\n",
    "sum_one = int(sum_one)\n",
    "sum_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dd3b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_delete = []\n",
    "count_zero = 0\n",
    "for i in range(targets.shape[0]):\n",
    "    if(targets[i] == 0):\n",
    "        count_zero += 1\n",
    "    if(count_zero > sum_one):\n",
    "        index_delete.append(i)\n",
    "\n",
    "inputs_balance = np.delete(unscaled_inputs, index_delete, axis=0)\n",
    "targets_balance = np.delete(targets, index_delete, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0a96a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., ..., 0., 0., 0.]),\n",
       " array([[2.160e+03, 2.160e+03, 1.013e+01, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [1.404e+03, 2.808e+03, 6.660e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         1.820e+02],\n",
       "        [3.240e+02, 3.240e+02, 1.013e+01, ..., 0.000e+00, 1.000e+00,\n",
       "         3.340e+02],\n",
       "        ...,\n",
       "        [2.160e+03, 2.160e+03, 1.013e+01, ..., 2.592e+02, 0.000e+00,\n",
       "         1.400e+01],\n",
       "        [2.160e+03, 2.160e+03, 8.300e+00, ..., 2.592e+02, 0.000e+00,\n",
       "         9.300e+01],\n",
       "        [2.160e+03, 2.160e+03, 8.000e+00, ..., 2.592e+02, 0.000e+00,\n",
       "         2.400e+01]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_balance, inputs_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c791e8",
   "metadata": {},
   "source": [
    "## Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d8d20cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.18956512,  0.36398846,  0.67728889, ..., -0.8635056 ,\n",
       "        -0.20536617, -0.77240946],\n",
       "       [-0.33022754,  1.10843845, -0.08841391, ..., -0.8635056 ,\n",
       "        -0.20536617,  1.16499791],\n",
       "       [-2.50135991, -1.74528653,  0.67728889, ..., -0.8635056 ,\n",
       "         2.23179102,  2.78305242],\n",
       "       ...,\n",
       "       [ 1.18956512,  0.36398846,  0.67728889, ..., -0.20129479,\n",
       "        -0.20536617, -0.62337812],\n",
       "       [ 1.18956512,  0.36398846,  0.27347444, ..., -0.20129479,\n",
       "        -0.20536617,  0.21758442],\n",
       "       [ 1.18956512,  0.36398846,  0.20727535, ..., -0.20129479,\n",
       "        -0.20536617, -0.51692717]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_inputs = preprocessing.scale(inputs_balance)\n",
    "standard_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae5602",
   "metadata": {},
   "source": [
    "## Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "878a3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.arange(targets_balance.shape[0])\n",
    "np.random.shuffle(shuffle_index)\n",
    "shuffle_index\n",
    "shuffle_inputs = inputs_balance[shuffle_index]\n",
    "shuffle_targets = targets_balance[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66547e",
   "metadata": {},
   "source": [
    "### Split the dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6873ec21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3579, 447, 447)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_counts = shuffle_targets.shape[0]\n",
    "\n",
    "train_sample_counts = int(0.8 * sample_counts)\n",
    "validation_sample_counts = int(0.1 * sample_counts)\n",
    "test_sample_counts = int(0.1 * sample_counts)\n",
    "train_sample_counts, validation_sample_counts, test_sample_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb1ea2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1785.0 3579 0.49874266554903607\n",
      "230.0 447 0.5145413870246085\n",
      "222.0 447 0.4966442953020134\n"
     ]
    }
   ],
   "source": [
    "train_inputs = shuffle_inputs[:train_sample_counts, :]\n",
    "train_targets  = shuffle_targets[:train_sample_counts]\n",
    "\n",
    "validation_inputs = shuffle_inputs[train_sample_counts:train_sample_counts + validation_sample_counts, :]\n",
    "validation_targets = shuffle_targets[train_sample_counts:train_sample_counts + validation_sample_counts]\n",
    "\n",
    "test_inputs = shuffle_inputs[sample_counts - test_sample_counts:, :]\n",
    "test_targets = shuffle_targets[sample_counts - test_sample_counts:]\n",
    "\n",
    "print(np.sum(train_targets), train_sample_counts, np.sum(train_targets) / train_sample_counts)\n",
    "print(np.sum(validation_targets), validation_sample_counts, np.sum(validation_targets) / validation_sample_counts)\n",
    "print(np.sum(test_targets), test_sample_counts, np.sum(test_targets) / test_sample_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28b0f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the three datasets in *.npz.\n",
    "# In the next lesson, you will see that it is extremely valuable to name them in such a coherent way!\n",
    "\n",
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df495d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
